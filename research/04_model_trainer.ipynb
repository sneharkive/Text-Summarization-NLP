{
 "cells": [
  {
   "metadata": {},
   "cell_type": "raw",
   "outputs": [],
   "execution_count": null,
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 1,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"import os\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 2,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"'d:\\\\\\\\Bappy\\\\\\\\YouTube\\\\\\\\Text-Summarizer-Project\\\\\\\\research'\"\n",
    "      ]\n",
    "     },\n",
    "     \"execution_count\": 2,\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"execute_result\"\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"%pwd\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 3,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"os.chdir(\\\"../\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 4,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"'d:\\\\\\\\Bappy\\\\\\\\YouTube\\\\\\\\Text-Summarizer-Project'\"\n",
    "      ]\n",
    "     },\n",
    "     \"execution_count\": 4,\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"execute_result\"\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"%pwd\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 5,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"from dataclasses import dataclass\\n\",\n",
    "    \"from pathlib import Path\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"@dataclass(frozen=True)\\n\",\n",
    "    \"class ModelTrainerConfig:\\n\",\n",
    "    \"    root_dir: Path\\n\",\n",
    "    \"    data_path: Path\\n\",\n",
    "    \"    model_ckpt: Path\\n\",\n",
    "    \"    num_train_epochs: int\\n\",\n",
    "    \"    warmup_steps: int\\n\",\n",
    "    \"    per_device_train_batch_size: int\\n\",\n",
    "    \"    weight_decay: float\\n\",\n",
    "    \"    logging_steps: int\\n\",\n",
    "    \"    evaluation_strategy: str\\n\",\n",
    "    \"    eval_steps: int\\n\",\n",
    "    \"    save_steps: float\\n\",\n",
    "    \"    gradient_accumulation_steps: int\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 6,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"from textSummarizer.constants import *\\n\",\n",
    "    \"from textSummarizer.utils.common import read_yaml, create_directories\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 7,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"class ConfigurationManager:\\n\",\n",
    "    \"    def __init__(\\n\",\n",
    "    \"        self,\\n\",\n",
    "    \"        config_filepath = CONFIG_FILE_PATH,\\n\",\n",
    "    \"        params_filepath = PARAMS_FILE_PATH):\\n\",\n",
    "    \"\\n\",\n",
    "    \"        self.config = read_yaml(config_filepath)\\n\",\n",
    "    \"        self.params = read_yaml(params_filepath)\\n\",\n",
    "    \"\\n\",\n",
    "    \"        create_directories([self.config.artifacts_root])\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    def get_model_trainer_config(self) -> ModelTrainerConfig:\\n\",\n",
    "    \"        config = self.config.model_trainer\\n\",\n",
    "    \"        params = self.params.TrainingArguments\\n\",\n",
    "    \"\\n\",\n",
    "    \"        create_directories([config.root_dir])\\n\",\n",
    "    \"\\n\",\n",
    "    \"        model_trainer_config = ModelTrainerConfig(\\n\",\n",
    "    \"            root_dir=config.root_dir,\\n\",\n",
    "    \"            data_path=config.data_path,\\n\",\n",
    "    \"            model_ckpt = config.model_ckpt,\\n\",\n",
    "    \"            num_train_epochs = params.num_train_epochs,\\n\",\n",
    "    \"            warmup_steps = params.warmup_steps,\\n\",\n",
    "    \"            per_device_train_batch_size = params.per_device_train_batch_size,\\n\",\n",
    "    \"            weight_decay = params.weight_decay,\\n\",\n",
    "    \"            logging_steps = params.logging_steps,\\n\",\n",
    "    \"            evaluation_strategy = params.evaluation_strategy,\\n\",\n",
    "    \"            eval_steps = params.evaluation_strategy,\\n\",\n",
    "    \"            save_steps = params.save_steps,\\n\",\n",
    "    \"            gradient_accumulation_steps = params.gradient_accumulation_steps\\n\",\n",
    "    \"        )\\n\",\n",
    "    \"\\n\",\n",
    "    \"        return model_trainer_config\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 8,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stderr\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"d:\\\\Softwares\\\\anaconda3\\\\envs\\\\textS\\\\lib\\\\site-packages\\\\tqdm\\\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\\n\",\n",
    "      \"  from .autonotebook import tqdm as notebook_tqdm\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"from transformers import TrainingArguments, Trainer\\n\",\n",
    "    \"from transformers import DataCollatorForSeq2Seq\\n\",\n",
    "    \"from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\\n\",\n",
    "    \"from datasets import load_dataset, load_from_disk\\n\",\n",
    "    \"import torch\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 9,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"class ModelTrainer:\\n\",\n",
    "    \"    def __init__(self, config: ModelTrainerConfig):\\n\",\n",
    "    \"        self.config = config\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    def train(self):\\n\",\n",
    "    \"        device = \\\"cuda\\\" if torch.cuda.is_available() else \\\"cpu\\\"\\n\",\n",
    "    \"        tokenizer = AutoTokenizer.from_pretrained(self.config.model_ckpt)\\n\",\n",
    "    \"        model_pegasus = AutoModelForSeq2SeqLM.from_pretrained(self.config.model_ckpt).to(device)\\n\",\n",
    "    \"        seq2seq_data_collator = DataCollatorForSeq2Seq(tokenizer, model=model_pegasus)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        #loading data \\n\",\n",
    "    \"        dataset_samsum_pt = load_from_disk(self.config.data_path)\\n\",\n",
    "    \"\\n\",\n",
    "    \"        # trainer_args = TrainingArguments(\\n\",\n",
    "    \"        #     output_dir=self.config.root_dir, num_train_epochs=self.config.num_train_epochs, warmup_steps=self.config.warmup_steps,\\n\",\n",
    "    \"        #     per_device_train_batch_size=self.config.per_device_train_batch_size, per_device_eval_batch_size=self.config.per_device_train_batch_size,\\n\",\n",
    "    \"        #     weight_decay=self.config.weight_decay, logging_steps=self.config.logging_steps,\\n\",\n",
    "    \"        #     evaluation_strategy=self.config.evaluation_strategy, eval_steps=self.config.eval_steps, save_steps=1e6,\\n\",\n",
    "    \"        #     gradient_accumulation_steps=self.config.gradient_accumulation_steps\\n\",\n",
    "    \"        # ) \\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"        trainer_args = TrainingArguments(\\n\",\n",
    "    \"            output_dir=self.config.root_dir, num_train_epochs=1, warmup_steps=500,\\n\",\n",
    "    \"            per_device_train_batch_size=1, per_device_eval_batch_size=1,\\n\",\n",
    "    \"            weight_decay=0.01, logging_steps=10,\\n\",\n",
    "    \"            evaluation_strategy='steps', eval_steps=500, save_steps=1e6,\\n\",\n",
    "    \"            gradient_accumulation_steps=16\\n\",\n",
    "    \"        ) \\n\",\n",
    "    \"\\n\",\n",
    "    \"        trainer = Trainer(model=model_pegasus, args=trainer_args,\\n\",\n",
    "    \"                  tokenizer=tokenizer, data_collator=seq2seq_data_collator,\\n\",\n",
    "    \"                  train_dataset=dataset_samsum_pt[\\\"train\\\"], \\n\",\n",
    "    \"                  eval_dataset=dataset_samsum_pt[\\\"validation\\\"])\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        trainer.train()\\n\",\n",
    "    \"\\n\",\n",
    "    \"        ## Save model\\n\",\n",
    "    \"        model_pegasus.save_pretrained(os.path.join(self.config.root_dir,\\\"pegasus-samsum-model\\\"))\\n\",\n",
    "    \"        ## Save tokenizer\\n\",\n",
    "    \"        tokenizer.save_pretrained(os.path.join(self.config.root_dir,\\\"tokenizer\\\"))\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 10,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"[2023-05-18 12:54:11,649: INFO: common: yaml file: config\\\\config.yaml loaded successfully]\\n\",\n",
    "      \"[2023-05-18 12:54:11,652: INFO: common: yaml file: params.yaml loaded successfully]\\n\",\n",
    "      \"[2023-05-18 12:54:11,654: INFO: common: created directory at: artifacts]\\n\",\n",
    "      \"[2023-05-18 12:54:11,655: INFO: common: created directory at: artifacts/model_trainer]\\n\"\n",
    "     ]\n",
    "    },\n",
    "    {\n",
    "     \"name\": \"stderr\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"d:\\\\Softwares\\\\anaconda3\\\\envs\\\\textS\\\\lib\\\\site-packages\\\\transformers\\\\optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\\n\",\n",
    "      \"  warnings.warn(\\n\",\n",
    "      \"  0%|          | 0/51 [00:00<?, ?it/s]You're using a PegasusTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\\n\",\n",
    "      \" 20%|█▉        | 10/51 [07:49<30:32, 44.70s/it]\"\n",
    "     ]\n",
    "    },\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"{'loss': 3.3137, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.2}\\n\"\n",
    "     ]\n",
    "    },\n",
    "    {\n",
    "     \"name\": \"stderr\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \" 39%|███▉      | 20/51 [14:44<21:16, 41.19s/it]\"\n",
    "     ]\n",
    "    },\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"{'loss': 3.1, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.39}\\n\"\n",
    "     ]\n",
    "    },\n",
    "    {\n",
    "     \"name\": \"stderr\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \" 59%|█████▉    | 30/51 [22:08<15:10, 43.37s/it]\"\n",
    "     ]\n",
    "    },\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"{'loss': 3.0839, 'learning_rate': 3e-06, 'epoch': 0.59}\\n\"\n",
    "     ]\n",
    "    },\n",
    "    {\n",
    "     \"name\": \"stderr\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \" 78%|███████▊  | 40/51 [29:04<07:32, 41.17s/it]\"\n",
    "     ]\n",
    "    },\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"{'loss': 2.9821, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.78}\\n\"\n",
    "     ]\n",
    "    },\n",
    "    {\n",
    "     \"name\": \"stderr\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \" 98%|█████████▊| 50/51 [35:40<00:34, 34.19s/it]\"\n",
    "     ]\n",
    "    },\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"{'loss': 3.1034, 'learning_rate': 5e-06, 'epoch': 0.98}\\n\"\n",
    "     ]\n",
    "    },\n",
    "    {\n",
    "     \"name\": \"stderr\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"100%|██████████| 51/51 [36:24<00:00, 42.84s/it]\\n\"\n",
    "     ]\n",
    "    },\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"{'train_runtime': 2184.9179, 'train_samples_per_second': 0.375, 'train_steps_per_second': 0.023, 'train_loss': 3.11656564357234, 'epoch': 1.0}\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"try:\\n\",\n",
    "    \"    config = ConfigurationManager()\\n\",\n",
    "    \"    model_trainer_config = config.get_model_trainer_config()\\n\",\n",
    "    \"    model_trainer_config = ModelTrainer(config=model_trainer_config)\\n\",\n",
    "    \"    model_trainer_config.train()\\n\",\n",
    "    \"except Exception as e:\\n\",\n",
    "    \"    raise e\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": []\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"textS\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.8.16\"\n",
    "  },\n",
    "  \"orig_nbformat\": 4\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 2\n",
    "}\n"
   ],
   "id": "e178e0be6ad41d6e"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
